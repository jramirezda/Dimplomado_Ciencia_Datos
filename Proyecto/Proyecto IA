Proyecto Inteligencia Artificial 2023-1 
Jhon Alejandro Ramirez Daza

En el presente estudio, se realizará la clasificación de imágenes utilizando redes neuronales convolucionales (CNN, por sus siglas en inglés). Se explorarán dos enfoques distintos: la creación de una red desde cero y el reentrenamiento de una red preentrenada mediante transfer learning. Estos métodos se aplicarán a un conjunto de datos compuesto por imágenes y etiquetas.

Las redes neuronales convolucionales son ampliamente utilizadas en tareas de visión por computadora, ya que son capaces de aprender patrones visuales y características relevantes en las imágenes. La creación de una red desde cero nos brinda la flexibilidad de diseñar la arquitectura a medida, mientras que el reentrenamiento de una red preentrenada permite aprovechar el conocimiento previo adquirido en conjuntos de datos masivos.

Para este estudio, se utilizará el conjunto de datos proporcionado en la siguiente [Imagenes orbital de Marte (HiRISE) conjunto de datos etiquetados versión 3.2](https://zenodo.org/record/4002935). Se trabajará en el preprocesamiento de las imágenes, la definición de las arquitecturas de las redes, el entrenamiento y la evaluación de los modelos resultantes.

## Descripción general de los datos

Este conjunto de datos contiene un total de 73,031 puntos de referencia. De estos, 10,433 puntos de referencia fueron detectados y extraídos de 180 imágenes de exploración de HiRISE, y 62,598 puntos de referencia fueron aumentados a partir de los 10,433 puntos de referencia originales.

Para cada punto de referencia original, se recortó una caja delimitadora cuadrada que incluye toda la extensión del punto de referencia más un margen de 30 píxeles a la izquierda, derecha, arriba y abajo. Cada punto de referencia recortado se redimensionó a 227x227 píxeles y luego se aumentó para generar 6 puntos de referencia adicionales utilizando los siguientes métodos:

Rotación de 90 grados en sentido horario
Rotación de 180 grados en sentido horario
Rotación de 270 grados en sentido horario
Volteo horizontal
Volteo vertical
Ajuste aleatorio de brillo
Este conjunto de datos es útil para la clasificación de imágenes de puntos de referencia en diferentes categorías. Los puntos de referencia se presentan como imágenes cuadradas de 227x227 píxeles, y cada imagen se ha aumentado para incluir variaciones en la orientación y el brillo. Además, se proporcionan etiquetas de clase para cada imagen, lo que permite la clasificación supervisada de los puntos de referencia utilizando técnicas de aprendizaje automático y de aprendizaje profundo.

las categorias que se usaron para etiquetar las imagenes son las siguientes: 

| Código | Descripción        |
|-------:|-------------------:|
|      0 |            other  |
|      1 |            crater |
|      2 |         dark dune |
|      3 |       slope streak |
|      4 |        bright dune |
|      5 |      impact ejecta |
|      6 |      swiss cheese  |
|      7 |   spider           |

En este proyecto, se utilizará un modelo preentrenado llamado VGG16 como base para realizar una tarea específica. El VGG16 es un modelo de red neuronal convolucional (CNN) ampliamente conocido y utilizado en la comunidad de aprendizaje profundo.

El objetivo es aprovechar el conocimiento previo del modelo VGG16, que ha sido entrenado en grandes conjuntos de datos de imágenes, para resolver nuestro problema específico. Sin embargo, se realizarán algunas modificaciones en el modelo para adaptarlo a nuestras necesidades.

En primer lugar, cargaremos el modelo VGG16 preentrenado sin incluir la capa densa superior. Esto significa que omitiremos la última capa completamente conectada del modelo, que se encarga de realizar predicciones específicas para el conjunto de datos original en el que se entrenó el modelo.

A continuación, congelaremos las capas existentes del modelo VGG16. Esto implica que no actualizaremos los pesos de estas capas durante el proceso de entrenamiento. Al congelar estas capas, evitamos que se modifiquen y nos permiten utilizar el conocimiento aprendido previamente en tareas similares.

Después de congelar las capas existentes, agregaremos capas adicionales al modelo. Estas capas adicionales se conectarán a la salida del modelo VGG16 y nos permitirán adaptar el modelo a nuestra tarea específica. En este caso, utilizaremos una capa de agrupamiento global promedio (Global Average Pooling), una capa de aplanamiento (Flatten), una capa densa con activación ReLU y una capa de dropout para regularización. Finalmente, agregaremos una capa densa de salida con activación softmax que producirá las predicciones finales para nuestras clases de interés.

El modelo final resultante se construirá utilizando las capas modificadas y se utilizará para reentrenar las últimas 10 capas del modelo. Estas capas se actualizarán durante el proceso de entrenamiento para adaptarse a nuestro conjunto de datos y resolver nuestra tarea específica.

Las modificaciones realizadas nos permiten aprovechar el conocimiento previo del modelo VGG16, mientras adaptamos el modelo a nuestra tarea específica. Al reentrenar las últimas capas, permitimos que el modelo se ajuste a nuestro conjunto de datos y aprenda a realizar predicciones precisas para nuestras clases de interés.

A través de este enfoque de transferencia de aprendizaje con el modelo VGG16 y las modificaciones realizadas, esperamos obtener un modelo eficiente y preciso para nuestra tarea específica.
